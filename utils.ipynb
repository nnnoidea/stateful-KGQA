{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# # file_path = './data/WebQuestions.json'\n",
    "def prepare_dataset(file_path):\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "# # dataset = prepare_dataset(file_path)\n",
    "# # for data in dataset[2:3]:\n",
    "# #     # print(data)\n",
    "# #     question = data['RawQuestion']\n",
    "# #     # print(question)\n",
    "\n",
    "# def str_match(info, entity_chains):\n",
    "#     return any(info in entity or entity in info for entity in entity_chains)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for llama\n",
    "\n",
    "entity_chain_prompt = \"\"\"\n",
    "please identify the entities in the sentence by taking into account the sentence's syntactic structure. \n",
    "Below is an example.\n",
    "sentence: Which place is the madam satan located?\n",
    "entities: ['place', 'madam satan']\n",
    "Now answer with the format of the example above.\n",
    "sentence: %s\n",
    "entities:\"\"\"\n",
    "\n",
    "prune_prompt = \"\"\"\n",
    "Please retrieve relations that are related to any of the target information from the sentence and rate it on a scale of 0 to 10. Be brief and concise.\n",
    "sentence: Name the president of the country whose main spoken language was Brahui in 1980?\n",
    "target information: ['president', 'country', 'main spoken language', 'Brahui', '1980']\n",
    "relations: ['language.human_language.main_country', 'language.human_language.human_language', 'language.human_language.language_family', 'language.human_language.iso_639_3_code', 'base.rosetta.languoid.parent', 'language.human_language.writing_system', 'base.rosetta.languoid.languoid_class'] \n",
    "assess: \n",
    "- 'language.human_language.main_country' is related to the country, so it's a match, (9) score.\n",
    "- 'language.human_language.human_language' is kind of related to the main spoken language, so it's a match, (6) score.\n",
    "- other relations are not related to any information in the sentence, so they are not match, (0) score.\n",
    "sentence: {}\n",
    "target information: {}\n",
    "relations: {}\n",
    "assess: \"\"\"\n",
    "\n",
    "select_node_prompt = \"\"\"\n",
    "Please assess the relevance of each candidate entity to the information in the sentence and assign a score ranging from 0 to 10. The format of the candidate entity is (relation, entity).\n",
    "sentence: Which place is the madam satan located?\n",
    "information in the sentence: ['place', 'madam satan']\n",
    "candidate entity: [('film.film.country', 'the USA'), ('film.film.language', 'English')]\n",
    "assess: \n",
    "- ('film.film.country', 'the USA') is related to 'place', so it's a match, (8) score.\n",
    "- ('film.film.language', 'English')is not related to any information in the sentence,(0) score.\n",
    "sentence: {}\n",
    "information in the sentence: {}\n",
    "candidate entity: {}\n",
    "assess: \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "answer_prompt = \"\"\"\n",
    "please answer the question based on the provided triplets. The format of the triplet is (entity1, relation, entity2). If there is not enough information provided in the triplets, answer the question with your own knowledge.\n",
    "question: Which place is the madam satan located?\n",
    "triplets: [('madam satan', 'film.film.country', 'the USA'), ('madam satan', 'film.film.language', 'English')]\n",
    "answer: 'madam satan' is located in 'the USA'.\n",
    "question: {}\n",
    "triplets: {}\n",
    "answer: \"\"\"\n",
    "\n",
    "\n",
    "def construct_entity_chain_prompt(question):\n",
    "    return entity_chain_prompt % question\n",
    "\n",
    "def construct_select_node_prompt(question, uninvovled_info, candidates):\n",
    "    return select_node_prompt.format(question, uninvovled_info, candidates)\n",
    "\n",
    "\n",
    "def construct_answer_prompt(question, routes):\n",
    "    return answer_prompt.format(question, routes)\n",
    "\n",
    "def construct_prune_prompt(question, aim_info, related_node):\n",
    "    return prune_prompt.format(question, aim_info, related_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_id = \"/models/Llama3-8B-Instruct/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model=model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_llama(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=512,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=False,\n",
    "        # temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    return tokenizer.decode(response, skip_special_tokens=True)\n",
    "\n",
    "#prompt = \"\"\"Who are you?\"\"\"\n",
    "#print(chat_llama(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def chat_gpt(prompt, model=\"gpt-3.5-turbo-16k\"):\n",
    "    client = OpenAI(\n",
    "        base_url=\"\",\n",
    "        api_key=\"\"\n",
    "    )\n",
    "\n",
    " \n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # 非流式输出获取结果\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# use_model = \"gpt-3.5-turbo-16k\"\n",
    "# use_model = \"gpt-4\"\n",
    "# use_model = \"glm-4-9b-chat\"\n",
    "use_model = \"llama\"\n",
    "\n",
    "response_path = 'llama_prompt_response.json'\n",
    "# response_path = 'chatgpt_prompt_response.json'\n",
    "#response_path = 'gpt4_prompt_response.json'\n",
    "# response_path = 'glm4_9b_chat_prompt_response.json'\n",
    "\n",
    "def extract_entity_chain(question, model=use_model):\n",
    "    prompt = construct_entity_chain_prompt(question)\n",
    "    if use_model == \"llama\":\n",
    "        response = chat_llama(prompt)\n",
    "    elif use_model == \"gpt-3.5-turbo-16k\":\n",
    "        response = chat_gpt(prompt, model=\"gpt-3.5-turbo-16k\")\n",
    "    elif use_model == \"gpt-4\":\n",
    "        response = chat_gpt(prompt, model=\"gpt-4\")\n",
    "    elif use_model == \"glm-4-9b-chat\":\n",
    "        response = glm4_9b_chat(prompt)\n",
    "\n",
    "    response = response.split('entities: ')[-1]\n",
    "\n",
    "    response = response.split('<|user|>')[0]\n",
    "\n",
    "    tmp = {}\n",
    "    tmp['prompt'] = [question]\n",
    "    tmp['response'] = response\n",
    "    with open(response_path, 'a', encoding='utf-8') as file:\n",
    "        file.write('extract_clues:  ')\n",
    "        json.dump(tmp, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "    # print(response)\n",
    "    new_list = ast.literal_eval(response)\n",
    "    # print(new_list)\n",
    "    return new_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune_node\n",
      "\n",
      "- 'common.topic.article' is related to 'st. louis park', but not directly to the county, (3) score.\n",
      "- 'common.topic.description' is related to 'st. louis park', but not directly to the county, (3) score.\n",
      "- 'base.ontologies.ontology_instance.equivalent_instances' could potentially be related to 'st. louis park' but not specifically to the county, (3) score.\n",
      "- Other relations are not directly related to the county, (0) score. <|user|>\n",
      "[('common.topic.article', '3'), ('st. louis park', '3'), ('common.topic.description', '3'), ('st. louis park', '3'), ('base.ontologies.ontology_instance.equivalent_instances', '3'), ('st. louis park', '3')]\n",
      "[('common.topic.article', '3'), ('st. louis park', '3'), ('common.topic.description', '3'), ('st. louis park', '3'), ('base.ontologies.ontology_instance.equivalent_instances', '3'), ('st. louis park', '3')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def relation_mapping(question, aim_info, entity, related_node, model=use_model):\n",
    "    prompt = construct_prune_prompt(question, aim_info, related_node)\n",
    "    if use_model == \"llama\":\n",
    "        response = chat_llama(prompt)\n",
    "    elif use_model == \"gpt-3.5-turbo-16k\":\n",
    "        response = chat_gpt(prompt, model=\"gpt-3.5-turbo-16k\")\n",
    "    elif use_model == \"gpt-4\":\n",
    "        response = chat_gpt(prompt, model=\"gpt-4\")\n",
    "    elif use_model == \"glm-4-9b-chat\":\n",
    "        response = glm4_9b_chat(prompt)\n",
    "    # print('relation_mapping: ')\n",
    "    # print(response)\n",
    "    response = response.split('assess:')[-1]\n",
    "    response = response.split('<|user|>')[0]\n",
    "    tmp = {}\n",
    "    tmp['prompt'] = [question, aim_info, entity, related_node]\n",
    "    tmp['response'] = response\n",
    "    with open(response_path, 'a', encoding='utf-8') as file:\n",
    "        file.write('relation_mapping:  ')\n",
    "        json.dump(tmp, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "    result = []\n",
    "    for line in response.split(\"\\n\"):\n",
    "        relation = []\n",
    "        for info in related_node:\n",
    "            if str(info) in line:\n",
    "                relation.append(info)\n",
    "        if len(relation) != 1:\n",
    "            continue\n",
    "        clues = []\n",
    "        for info in aim_info:\n",
    "            if info in line:\n",
    "                clues.append(info)\n",
    "        seg = line.split(',')\n",
    "        if 'score' in seg[-1]:\n",
    "            scores = re.findall(r'\\d+', seg[-1])\n",
    "        else:\n",
    "            scores = []\n",
    "        if scores == []:\n",
    "            continue\n",
    "        print(relation, clues, scores)\n",
    "        if clues == [] or int(scores[0]) < 5:\n",
    "            continue\n",
    "        for clue in clues:\n",
    "            result.append((relation[0], clue, scores[0]))\n",
    "        print(result)\n",
    "        if len(result) > 1:\n",
    "            result.sort(key=lambda x: int(x[2]), reverse=True)\n",
    "            result = result\n",
    "    return result\n",
    "\n",
    "# q = \"what county is st. louis park in?\" \n",
    "# aim_info = ['county', 'st. louis park'] \n",
    "# entity = ('county', 'st. louis park') \n",
    "# rn = ['common.topic.article', 'common.topic.description', 'common.topic.image', 'common.topic.webpage', 'user.avh.default_domain.ellerdale_topic.ellerdale_id','base.ontologies.ontology_instance.equivalent_instances','common.image.appears_in_topic_gallery','base.ontologies.ontology_instance_mapping.freebase_topic']\n",
    "# print(prune_node(q, aim_info, entity, rn))\n",
    "\n",
    "def entity_mapping(question, uninvovled_info, candidates, model=use_model):\n",
    "    prompt = construct_select_node_prompt(question, uninvovled_info, candidates)\n",
    "    if use_model == \"llama\":\n",
    "        response = chat_llama(prompt)\n",
    "    elif use_model == \"gpt-3.5-turbo-16k\":\n",
    "        response = chat_gpt(prompt, model=\"gpt-3.5-turbo-16k\")\n",
    "    elif use_model == \"gpt-4\":\n",
    "        response = chat_gpt(prompt, model=\"gpt-4\")\n",
    "    elif use_model == \"glm-4-9b-chat\":\n",
    "        response = glm4_9b_chat(prompt)\n",
    "    # print('entity_mapping:')\n",
    "    # print(response)\n",
    "    # response = \"\"\"- ('county', ' hennepin county, minnesota') is related to 'county', so it's a match, (9) score.\\n- ('location.location.containedby', 'chicago, milwaukee, st. paul and pacific depot (st. louis park, minnesota)') is related to 'location.location.containedby', 'st. louis park', so it's a match, (8) score.\\n- ('location.location.containedby', 'University of Phoenix-Minneapolis/St Paul Campus') is not related to any information in the sentence,(0) score.\\n- ('location.location.containedby', 'Toby Keith's I Love This Bar & Grill') is not related to any information in the sentence,(0) score.\\n- ('location.location.containedby', 'DeVry University-Minnesota') is not related to any information in the sentence,(0) score.\"\"\"\n",
    "    response = response.split('assess:')[-1]\n",
    "    response = response.split('<|user|>')[0]\n",
    "    tmp = {}\n",
    "    tmp['prompt'] = [question, uninvovled_info, candidates]\n",
    "    tmp['response'] = response\n",
    "    with open(response_path, 'a', encoding='utf-8') as file:\n",
    "        file.write('entity_mapping:  ')\n",
    "        json.dump(tmp, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for line in response.split(\"\\n\"):\n",
    "        relation = []\n",
    "        for info in candidates:\n",
    "            if str(info) in line:\n",
    "                relation.append(info)\n",
    "        if len(relation) != 1:\n",
    "            continue\n",
    "        clues = []\n",
    "        for info in uninvovled_info:\n",
    "            if info in line:\n",
    "                clues.append(info)\n",
    "        seg = line.split(',')\n",
    "        if 'score' in seg[-1]:\n",
    "            scores = re.findall(r'\\d+', seg[-1])\n",
    "        else:\n",
    "            scores = []\n",
    "        if scores == []:\n",
    "            continue\n",
    "        if clues == [] or scores[0] == '0':\n",
    "            continue\n",
    "        for clue in clues:\n",
    "            if clue not in uninvovled_info:\n",
    "                continue\n",
    "            result.append((relation[0], clue, scores[0]))\n",
    "    return result\n",
    "# c = [[\"location.location.containedby\", \"united states\"], [\"location.location.containedby\", \"minnesota\"], [\"location.location.containedby\", \"hennepin county, minnesota\"], [\"location.location.containedby\", \"minneapolis – saint paul\"], [\"location.location.containedby\", \"Toby Keith's I Love This Bar & Grill\"], [\"location.location.containedby\", \"University of Phoenix-Minneapolis/St Paul Campus\"], [\"location.location.containedby\", \"chicago, milwaukee, st. paul and pacific depot (st. louis park, minnesota)\"], [\"location.location.containedby\", \"DeVry University-Minnesota\"]]\n",
    "# q = \"what county is st. louis park in?\"\n",
    "# ui = ['county'] \n",
    "# # c = [('location.location.containedby', 'italy'), ('location.location.containedby', 'province of cremona'), ('location.location.containedby', 'lombardy')]\n",
    "# print(select_node(q, ui, c))\n",
    "\n",
    "def answer_question(question, routes, model=use_model):\n",
    "    s = ''\n",
    "    for r in routes:\n",
    "        s += str(r) + ', '\n",
    "    prompt = construct_answer_prompt(question, s)\n",
    "    if use_model == \"llama\":\n",
    "        response = chat_llama(prompt)\n",
    "    elif use_model == \"gpt-3.5-turbo-16k\":\n",
    "        response = chat_gpt(prompt, model=\"gpt-3.5-turbo-16k\")\n",
    "    elif use_model == \"gpt-4\":\n",
    "        response = chat_gpt(prompt, model=\"gpt-4\")\n",
    "    elif use_model == \"glm-4-9b-chat\":\n",
    "        response = glm4_9b_chat(prompt)\n",
    "    print('answer:')\n",
    "    print(response)\n",
    "    response = response.replace(prompt, '').split('sentence:')[0].strip()\n",
    "    response = response.split('Please let me know')[0].strip('\\n')\n",
    "    response = response.split('<|user|>')[0]\n",
    "    tmp = {}\n",
    "    tmp['prompt'] = prompt\n",
    "    tmp['response'] = response\n",
    "    with open(response_path, 'a', encoding='utf-8') as file:\n",
    "        file.write('answer:  ')\n",
    "        json.dump(tmp, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "    return response\n",
    "\n",
    "# print(answer_question(\"where did drew brees go to college wikianswers?\",[]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "name_dict = {}\n",
    "\n",
    "def read_MapName():\n",
    "    map_list = []\n",
    "    with open(\"./mid2name.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            try:\n",
    "                map_list = re.split(r\"\\t\", line)\n",
    "                map_list[0] = map_list[0].replace(\"/\", \".\")[1:]\n",
    "                map_list[1] = map_list[1].strip(\"\\n\").lower()\n",
    "                if map_list[0] in name_dict:\n",
    "                    v = name_dict[map_list[0]]\n",
    "                    v.append(map_list[1])\n",
    "                    name_dict[map_list[0]] = v\n",
    "                else:\n",
    "                    name_dict[map_list[0]] = [map_list[1]]\n",
    "                if map_list[1] in name_dict:\n",
    "                    v = name_dict[map_list[1]]\n",
    "                    v.append(map_list[0])\n",
    "                    name_dict[map_list[1]] = v\n",
    "                else:\n",
    "                    name_dict[map_list[1]] = [map_list[0]]\n",
    "            except Exception as e:\n",
    "                print(f\"The row {map_list} has error!!!\")\n",
    "                print(e)\n",
    "                return\n",
    "\n",
    "read_MapName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def query_node_by_id(id):\n",
    "    if id in name_dict:\n",
    "        nodes = []\n",
    "        for name in name_dict[id]:\n",
    "            nodes.append(('', name, id))\n",
    "        return nodes\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def query_node_by_name(name):\n",
    "    name = name.lower()\n",
    "    if name in name_dict:\n",
    "        nodes = []\n",
    "        for id in name_dict[name]:\n",
    "            nodes.append(('', name, id))\n",
    "        return nodes\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "def get_wikidata_name(id):\n",
    "    url = \"http://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbgetentities\",\n",
    "        \"ids\": id,\n",
    "        \"format\": \"json\",\n",
    "        \"props\": \"labels\",\n",
    "        \"languages\": \"en\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # Get the label in English\n",
    "    label = data['entities'][id]['labels']['en']['value']\n",
    "    return label\n",
    "\n",
    "# from TOG freebase_func\n",
    "SPARQLPATH = \"\"\n",
    "\n",
    "def get_id_from_base(entity_id):\n",
    "    sparql_id = \"\"\"select DISTINCT ?e where {<id> <http://rdf.freebase.com/ns/type.object.name> ?e.}\n",
    "            \"\"\".replace(\"id\", \"http://rdf.freebase.com/ns/\" + entity_id)\n",
    "    sparql = SPARQLWrapper(SPARQLPATH)\n",
    "    sparql.setQuery(sparql_id)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    if len(results[\"results\"][\"bindings\"]) > 0:\n",
    "        return results[\"results\"][\"bindings\"][0]['e']['value']\n",
    "    \n",
    "    sparql_id = \"\"\"select DISTINCT ?e where {<id> <http://www.w3.org/2002/07/owl#sameAs> ?e.}\n",
    "            \"\"\".replace(\"id\", \"http://rdf.freebase.com/ns/\" + entity_id)\n",
    "    sparql = SPARQLWrapper(SPARQLPATH)\n",
    "    sparql.setQuery(sparql_id)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    if len(results[\"results\"][\"bindings\"]) > 0:\n",
    "        id = results[\"results\"][\"bindings\"][0]['e']['value']\n",
    "        id = id.split('/')[-1]\n",
    "        return get_wikidata_name(id)\n",
    "    return \"UnName_Entity\"\n",
    "\n",
    "\n",
    "# print(query_node_by_name(\"romney\"))\n",
    "\n",
    "# print(query_node_by_id('m.015_hb'))\n",
    "# print(get_id_from_base('m.015_hb'))\n",
    "# Count unique entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install SPARQLWrapper\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import re\n",
    "\n",
    "SPARQLPATH = \"\"\n",
    "\n",
    "def get_name_by_id(id):\n",
    "    if id in name_dict:\n",
    "        return name_dict[id][0]\n",
    "    return get_id_from_base(id)\n",
    "\n",
    "# print(get_name_by_id('g.125g4ph1r'))\n",
    "\n",
    "def get_directed_related_nodes_by_id(id, tail = True):   # 根据一个节点查询所有其他所有的关系和对应的尾节点\n",
    "    result = []\n",
    "    sparql = SPARQLWrapper(SPARQLPATH)\n",
    "    #print('before')\n",
    "    if tail:\n",
    "        sparql_txt = \"\"\"select DISTINCT ?r ?e where {<id> ?r ?e.} limit 1000\n",
    "            \"\"\".replace(\"id\", \"http://rdf.freebase.com/ns/\" + id)\n",
    "    else:\n",
    "        sparql_txt = \"\"\"select DISTINCT ?r ?e where {?e ?r <id>.} limit 1000\n",
    "            \"\"\".replace(\"id\", \"http://rdf.freebase.com/ns/\" + id)\n",
    "    sparql.setQuery(sparql_txt)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    #print('here')\n",
    "    # for i in results['results']['bindings']:\n",
    "    #     print(i)\n",
    "    try:\n",
    "        for item in results['results']['bindings']:\n",
    "            node_id = ''\n",
    "            if item['r']['value'].split('/')[-1] in ['type.object.name', 'owl#sameAs']:\n",
    "                continue\n",
    "            if item['e']['type'] == 'uri':\n",
    "                node_id = item['e']['value'].split('/')[-1]\n",
    "                if node_id[0] != 'm':\n",
    "                    continue\n",
    "                name = get_name_by_id(node_id)\n",
    "                \n",
    "            else:\n",
    "                name = item[\"e\"][\"value\"]\n",
    "            r = item[\"r\"][\"value\"].replace(\"http://rdf.freebase.com/ns/\", \"\")\n",
    "            result.append((r, name, node_id, r))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return result\n",
    "\n",
    "def get_related_nodes_by_id(id):\n",
    "    results = get_directed_related_nodes_by_id(id, True)\n",
    "    results.extend(get_directed_related_nodes_by_id(id, False))\n",
    "    return results\n",
    "\n",
    "# print(get_directed_related_nodes_by_id('m.078w2'))\n",
    "# print(get_related_nodes_by_id('m.07qymj'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myjupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
