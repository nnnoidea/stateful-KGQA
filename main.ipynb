{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ee0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import Ipynb_importer\n",
    "from utils import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c210138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def co_nodes(route1, route2):\n",
    "    nodes1 = [(node[0], node[1]) for node in route1]\n",
    "    nodes2 = [(node[0], node[1]) for node in route2]\n",
    "    if len(nodes2) == 1:\n",
    "        return False\n",
    "    for node in nodes1:\n",
    "        if node in nodes2:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def combine(routes, infos, clues):\n",
    "    rst_routes = []\n",
    "    all_info = []\n",
    "    rst_flag = False   ### true means all clues are found, false means not all but the most clues are found\n",
    "    for info in infos:\n",
    "        all_info.extend(info)\n",
    "    all_info = set(all_info)\n",
    "    if all_info == set(clues):\n",
    "        rst_flag = True\n",
    "\n",
    "    for i in range(len(routes) - 1):\n",
    "        rst_routes = []\n",
    "        rst_routes.append(routes[i])\n",
    "        rst_info = set(infos[i])\n",
    "        tmp_nodes = deepcopy(routes[i])\n",
    "        for j in range(i+1, len(routes)):\n",
    "            # print(rst_routes)\n",
    "            # print(routes[j])\n",
    "            flag = co_nodes(tmp_nodes, routes[j])\n",
    "            if flag:\n",
    "                rst_routes.append(routes[j])\n",
    "                rst_info = rst_info.union(infos[j])\n",
    "                tmp_nodes.extend(routes[j])\n",
    "        \n",
    "        if rst_info == all_info:\n",
    "            break\n",
    "    return rst_routes, rst_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68448aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if __name__ == '__main__':\n",
    "    # knowledge_labels = get_all_labels()\n",
    "\n",
    "    data_path = ''\n",
    "\n",
    "\n",
    "    datas = prepare_dataset(data_path)\n",
    "\n",
    "    count = 0\n",
    "    for data in datas:\n",
    "        count+=1\n",
    "        llm_call = 1\n",
    "        question = data['RawQuestion']\n",
    "        # question = data['question']\n",
    "        print('question:', question)\n",
    "        \n",
    "        # Modify question if the first word is 'where', 'when', or 'why'\n",
    "        first_word = question.split()[0]\n",
    "        if first_word.lower() in ['where', 'when', 'who']:\n",
    "            if first_word.lower() == 'where':\n",
    "                question = ' '.join(['which place', *question.split()[1:]])\n",
    "            elif first_word.lower() == 'when':\n",
    "                question = ' '.join(['what time', *question.split()[1:]])\n",
    "            elif first_word.lower() == 'who':\n",
    "                question = ' '.join(['which person', *question.split()[1:]])\n",
    "\n",
    "        \n",
    "        ##--------------------------------------------------------------------------------------------------------------\n",
    "        try :\n",
    "            clue_chains = extract_entity_chain(question)\n",
    "            print('clue_chains:', clue_chains)\n",
    "            if clue_chains[0] in ['place', 'time', 'person']:\n",
    "                clue_chains = clue_chains[1:] + clue_chains[:1]\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        print('clues:', clue_chains)\n",
    "        init_routes = []\n",
    "        init_info = []\n",
    "        \n",
    "        possible_routes = [] # 如果找不到下个节点（this_info为空），并且还有别的信息没找到，就保存到这里，最后一个tuple里存的是没找到的信息。\n",
    "        possible_info = []\n",
    "        \n",
    "        \n",
    "\n",
    "        for entity in clue_chains:\n",
    "            nodes = query_node_by_name(entity)\n",
    "            if nodes:\n",
    "                for node in nodes:\n",
    "                        init_routes.append([node])\n",
    "                        init_info.append([entity])\n",
    "                        break\n",
    "        direct_answer = 0\n",
    "        end_flag = 0\n",
    "        if init_routes == []:\n",
    "            print('no nodes found')\n",
    "            direct_answer = 1\n",
    "        depth = 0\n",
    "        end_flag = 0\n",
    "        current_routes = []\n",
    "        for i in range(len(init_routes)):\n",
    "         if end_flag == 1:\n",
    "             break\n",
    "         invovled_info = []\n",
    "         current_routes = []\n",
    "         current_routes.append(init_routes[i])\n",
    "         invovled_info.append(init_info[i])\n",
    "         while depth < len(clue_chains) and direct_answer == 0:\n",
    "            if llm_call > 30:\n",
    "                print('!!!!!!!!!!!!!!!!!!!!!!! llm_call: ', llm_call)\n",
    "                break\n",
    "            depth += 1    \n",
    "            \n",
    "            new_routes = []\n",
    "            new_info = []\n",
    "            for i in range(len(current_routes)): \n",
    "               if llm_call > 30:\n",
    "                   print('!!!!!!!!!!!!!!!!!!!!!!! llm_call: ', llm_call)\n",
    "                   break     \n",
    "               try:    \n",
    "                route = current_routes[i] # \n",
    "                # print('route:', route)\n",
    "                current_info = invovled_info[i] #对应于route的信息\n",
    "                print('current_info:', current_info)\n",
    "                related_nodes = get_related_nodes_by_id(route[-1][2]) # 每个节点都是(label, name, id, relation)\n",
    "                print('related_nodes of ', route[-1][1], \": \",related_nodes)\n",
    "                if len(route) > 1:\n",
    "                    related_nodes = [node for node in related_nodes if node[2] != route[-2][2]]\n",
    "                candidates = [] #候选节点，不包含name完全匹配的节点，要送给大模型选择的\n",
    "                current_flag = 0\n",
    "                for related_node in related_nodes:  ### (label, name, id, relation)\n",
    "                    #先字符匹配，name完全匹配优先级最高，没有的话直接剪枝\n",
    "                    if related_node[1] in clue_chains and related_node[1] not in current_info:\n",
    "                        new_routes.append(route+[related_node])\n",
    "                        tmp_info = current_info+[related_node[1]]\n",
    "                        current_flag = 1\n",
    "                        print('name matched:', related_node[1])\n",
    "                        if related_node[0] in clue_chains and related_node[0] not in current_info:\n",
    "                            tmp_info.append(related_node[0])\n",
    "                        if related_node[3] in clue_chains and related_node[3] not in current_info:\n",
    "                            tmp_info.append(related_node[3])\n",
    "                        tmp_info = list(set(tmp_info))\n",
    "                        new_info.append(tmp_info)\n",
    "\n",
    "                if current_flag == 1:\n",
    "                    continue\n",
    "\n",
    "                clue_2_relation = {}\n",
    "                # 仍然没有找到匹配的节点，就利用大模型进行剪枝\n",
    "                if current_flag == 0:\n",
    "                    extracted_nodes = [r for _, _, _, r in related_nodes]\n",
    "                    # pruned_nodes = [relation, clue, score]\n",
    "                    extracted_nodes = list(set(extracted_nodes))\n",
    "                    \n",
    "                    mapped_nodes = []\n",
    "                    \n",
    "                    while len(extracted_nodes) > 20:\n",
    "                        tmp = relation_mapping(question, list(set(clue_chains)-set(current_info)), (route[-1][0], route[-1][1]), extracted_nodes[:20])\n",
    "                        llm_call += 1\n",
    "                        mapped_nodes.extend(tmp)\n",
    "                        extracted_nodes = extracted_nodes[20:]\n",
    "                    tmp = relation_mapping(question, list(set(clue_chains)-set(current_info)), (route[-1][0], route[-1][1]), extracted_nodes)\n",
    "                    mapped_nodes.extend(tmp)\n",
    "                    print('mapped_nodes: ', mapped_nodes)\n",
    "                    llm_call += 1\n",
    "                    for node in mapped_nodes:\n",
    "                        tmp = []\n",
    "                        for related_node in related_nodes:\n",
    "                            if related_node[0] == node[0]:\n",
    "                                candidates.append(related_node)\n",
    "                                tmp.append(related_node)\n",
    "                        if tmp != []:\n",
    "                            clue_2_relation[node[1]] = clue_2_relation.get(node[1], []) + tmp\n",
    "\n",
    "                \n",
    "                if candidates != []:\n",
    "                        tmp_candi = deepcopy(candidates)\n",
    "                        tmp_candi = [(cand[0], cand[1]) for cand in tmp_candi]\n",
    "                        mapped_nodes = []\n",
    "                        if len(tmp_candi) > 80:\n",
    "                            tmp_candi = tmp_candi[:80]\n",
    "                        while len(tmp_candi) > 20:\n",
    "                            temp = tmp_candi[:20]\n",
    "                            tmp_candi = tmp_candi[20:]  \n",
    "                            selected_nodes = entity_mapping(question, list(set(clue_chains)-set(current_info)), temp)\n",
    "                            mapped_nodes.extend(selected_nodes)\n",
    "                            llm_call += 1\n",
    "                            print('llm_call:', llm_call)\n",
    "                        selected_nodes = entity_mapping(question, list(set(clue_chains)-set(current_info)), tmp_candi)\n",
    "    \n",
    "                        llm_call += 1\n",
    "                        print('llm_call:', llm_call)\n",
    "                        mapped_nodes.extend(selected_nodes)\n",
    "                        print('mapped_nodes:', mapped_nodes)\n",
    "\n",
    "                        for e_node in mapped_nodes:\n",
    "                            exsit_flag = 0\n",
    "                            for k, v in clue_2_relation.items():\n",
    "                                for node in v:\n",
    "                                    # print('node:', node)\n",
    "                                    # print('e_node:', e_node)\n",
    "                                    if node[0] == e_node[0][0] and node[1] == e_node[0][1]:\n",
    "                                        exsit_flag = 1\n",
    "                                        new_routes.append(route+[node])\n",
    "                                        if e_node[1] == k:\n",
    "                                            new_info.append(current_info+[k])\n",
    "                                        else:\n",
    "                                            new_info.append(current_info+[e_node[1], k])\n",
    "                            if exsit_flag == 0:\n",
    "                                mapped_nodes.remove(e_node)\n",
    "\n",
    "                        if len(mapped_nodes) == 0 and len(set(clue_chains)-set(current_info)) == 1:\n",
    "                            ### 如果只剩一个线索，且上面的关系映射有这个线索而实体映射没有，考虑是多选题的情况\n",
    "                            for k, v in clue_2_relation.items():\n",
    "                                if k == list(set(clue_chains)-set(current_info))[0]:\n",
    "                                    for node in v:\n",
    "                                        new_routes.append(route+[node])\n",
    "                                        new_info.append(current_info+[k])\n",
    "                        elif len(mapped_nodes) == 0:\n",
    "                            possible_routes.append(route)\n",
    "                            possible_info.append(current_info)\n",
    "\n",
    "                else:\n",
    "                    possible_routes.append(route)\n",
    "                    possible_info.append(current_info)\n",
    "                        \n",
    "\n",
    "               except Exception as e:\n",
    "                    print(e)\n",
    "                    continue \n",
    "            if new_routes != []:\n",
    "                current_routes = []\n",
    "                for i in range(len(new_info)):\n",
    "                    if set(new_info[i]) == set(clue_chains):\n",
    "                        end_flag = 1\n",
    "                        current_routes.append(new_routes[i])\n",
    "                if end_flag == 0:\n",
    "                    current_routes = new_routes\n",
    "                    invovled_info = new_info\n",
    "            else:\n",
    "                print('clues undiscovered')\n",
    "                break\n",
    "\n",
    "            if end_flag == 1:\n",
    "                break\n",
    "        # print('possible:', possible_routes)\n",
    "        # print('current:', current_routes)\n",
    "\n",
    "        if end_flag == 0 and direct_answer == 0: ### 如果没有找到所有的线索，就把可能的线索和信息都合并起来\n",
    "            all_routes = current_routes + possible_routes\n",
    "            all_infos = invovled_info + possible_info\n",
    "            current_routes, flag = combine(all_routes, all_infos, clue_chains)\n",
    "\n",
    "        info_2_llm = []\n",
    "        for route in current_routes:\n",
    "            if len(route) == 1:\n",
    "                info_2_llm.append((route[0][1], None, None))\n",
    "            else:\n",
    "                tmp = [(route[i][1], route[i+1][3], route[i+1][1]) for i in range(len(route)-1)]\n",
    "                for t in tmp:\n",
    "                    if t not in info_2_llm:\n",
    "                        info_2_llm.append(t)\n",
    "                \n",
    "\n",
    "        if len(info_2_llm) > 30:\n",
    "            info_2_llm = info_2_llm[:30]\n",
    "        print(info_2_llm)\n",
    "\n",
    "\n",
    "        try:\n",
    "            \n",
    "            answer_gpt = answer_question(question, info_2_llm)\n",
    "            if end_flag == 1:\n",
    "                answer_all_clues = answer_gpt\n",
    "            else:\n",
    "                answer_all_clues = chat_llama('please answer the question step by step:' + question)\n",
    "            llm_call += 1\n",
    "        except Exception as e:\n",
    "            answer_gpt = e\n",
    "\n",
    "\n",
    "        result3 = {\n",
    "            'data': data,\n",
    "            'answer': answer_gpt,\n",
    "            'llm_call': llm_call,\n",
    "            'answer_all_clues': answer_all_clues\n",
    "        }\n",
    "\n",
    "\n",
    "        with open('./results/webqsp.json', 'a', encoding='utf-8') as file:\n",
    "            try:\n",
    "                json.dump(result3, file, ensure_ascii=False)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(result3)\n",
    "            file.write('\\n')\n",
    "            file.write(str(info_2_llm))\n",
    "            file.write('\\n')\n",
    "        print(count, 'done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myjupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
